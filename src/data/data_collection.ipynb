{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "from utils import save_pandas_object\n",
    "\n",
    "from credentials import (\n",
    "    BEARER_TOKEN,\n",
    "    API_KEY,\n",
    "    API_SECRET,\n",
    "    ACCESS_TOKEN,\n",
    "    ACCESS_TOKEN_SECRET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Definimos los secret tokens para la escucha y se inicia el cliente\n",
    "bearer_token = BEARER_TOKEN\n",
    "api_key = API_KEY\n",
    "api_secret = API_SECRET\n",
    "access_token = ACCESS_TOKEN\n",
    "access_token_secret = ACCESS_TOKEN_SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(\n",
    "    bearer_token,\n",
    "    api_key,\n",
    "    api_secret,\n",
    "    access_token,\n",
    "    access_token_secret,\n",
    "    wait_on_rate_limit=True,\n",
    ")\n",
    "\n",
    "# Se inicializa la API\n",
    "auth = tweepy.OAuthHandler(\n",
    "    api_key,\n",
    "    api_secret,\n",
    ")\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par치metros\n",
    "search_terms = [\"barcelona\"]\n",
    "parts = 2\n",
    "number_of_tweets = 5\n",
    "desired_language = \"es\"\n",
    "folder_name = \"barcelona\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStream(tweepy.StreamingClient):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bearer_token,\n",
    "        desired_language=\"es\",\n",
    "        parts=1,\n",
    "        number_of_tweets=0,\n",
    "        folder_name=\"\",\n",
    "    ):\n",
    "        super().__init__(bearer_token)\n",
    "        self.desired_language = desired_language\n",
    "        self.parts = 1\n",
    "        self.number_of_tweets = 0\n",
    "        self.tweets = []\n",
    "        self.folder_name = folder_name\n",
    "\n",
    "    def on_connect(self):\n",
    "        print(\"Connected\")\n",
    "\n",
    "    def on_tweet(self, tweet):\n",
    "        retweeted_status = tweet.get(\"retweeted_status\")\n",
    "        if not retweeted_status and tweet.get(\"lang\") == self.desired_language:\n",
    "            time.sleep(0.2)\n",
    "            self.process_tweet(tweet)\n",
    "\n",
    "    def process_tweet(self, tweet):\n",
    "        extended_tweet = tweet.get(\"extended_tweet\")\n",
    "        if extended_tweet:\n",
    "            text = extended_tweet.get(\"full_text\")\n",
    "        else:\n",
    "            text = tweet.get(\"text\")\n",
    "\n",
    "        referenced_tweets = tweet.get(\"referenced_tweets\")\n",
    "        author_id = tweet.get(\"author_id\")\n",
    "        created_at = tweet.get(\"created_at\")\n",
    "\n",
    "        tweet_data = {\n",
    "            \"created_at\": created_at,\n",
    "            \"text\": tweet[\"text\"],\n",
    "            \"public_metrics\": tweet.get(\"public_metrics\"),\n",
    "            \"context_annotations\": tweet.get(\"context_annotations\"),\n",
    "            \"entities\": tweet.get(\"entities\"),\n",
    "            \"referenced_tweets\": referenced_tweets,\n",
    "        }\n",
    "\n",
    "        self.tweets.append(tweet_data)\n",
    "        self.number_of_tweets += 1\n",
    "\n",
    "    def on_data(self, raw_data):\n",
    "        try:\n",
    "            tweet = json.loads(raw_data)[\"data\"]\n",
    "            self.on_tweet(tweet)\n",
    "            time.sleep(0.2)\n",
    "            if self.number_of_tweets == number_of_tweets:\n",
    "                print(f\"Entered writing part {self.parts}\")\n",
    "                name = f\"data_{self.parts}.csv\"\n",
    "                df = pd.DataFrame(self.tweets)\n",
    "                save_pandas_object(df, \"..\\data\", self.folder_name, name)\n",
    "                self.number_of_tweets = 0\n",
    "                self.tweets = []\n",
    "                self.parts += 1\n",
    "            if self.parts == parts:\n",
    "                self.disconnect()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def on_disconnect(self):\n",
    "        print(\"Disconnected\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escucha Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = MyStream(\n",
    "    bearer_token=bearer_token,\n",
    "    desired_language=desired_language,\n",
    "    parts=parts,\n",
    "    number_of_tweets=number_of_tweets,\n",
    "    folder_name=folder_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 1 queries previos\n"
     ]
    }
   ],
   "source": [
    "# Eliminar reglas anteriores\n",
    "result_count = stream.get_rules().meta[\"result_count\"]\n",
    "print(f\"Hay {result_count} queries previos\")\n",
    "if result_count > 0:\n",
    "    for i in range(result_count):\n",
    "        prev_id = stream.get_rules().data[0].id\n",
    "        stream.delete_rules(prev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se a침ade el query 'barcelona'\n"
     ]
    }
   ],
   "source": [
    "# A침adir nuevas reglas\n",
    "for term in search_terms:\n",
    "    print(f\"Se a침ade el query '{term}'\")\n",
    "    stream.add_rules(tweepy.StreamRule(term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream connection closed by Twitter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered writing part 1\n",
      "Root directory already exists at ..\\data\\barcelona\n",
      "Disconnected\n"
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "stream.filter(\n",
    "    tweet_fields=[\n",
    "        \"referenced_tweets\",\n",
    "        \"entities\",\n",
    "        \"created_at\",\n",
    "        \"public_metrics\",\n",
    "        \"context_annotations\",\n",
    "        \"lang\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
